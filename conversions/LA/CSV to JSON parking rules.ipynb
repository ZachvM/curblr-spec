{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RULES = 4\n",
    "ROWS_TO_PROCESS = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract regulations from a row\n",
    "def get_regulations(row,number=None):\n",
    "    suffix = \"_\"+str(number) if number else \"\"\n",
    "     \n",
    "    regulation = {}\n",
    "   \n",
    "    rule = {}\n",
    "    \n",
    "    if len(row.get('zone'+suffix)):\n",
    "        rule['activity'] = row.get('zone'+suffix)\n",
    "    \n",
    "    if row.get('reason'+suffix):\n",
    "        rule['reason'] = row.get('reason'+suffix)\n",
    "    \n",
    "    if row.get('timeLimit'+suffix):\n",
    "        rule['maxStay'] = int(row.get('time_limit'+suffix))\n",
    "        \n",
    "    if row.get('payment'+suffix):\n",
    "        rule['payment'] = bool(row.get('payment'+suffix))\n",
    "    \n",
    "    if len(rule):\n",
    "        regulation['rule'] = rule\n",
    "\n",
    "\n",
    "            \n",
    "    userClass = {}\n",
    "    \n",
    "    if row.get('classes'+suffix):\n",
    "        userClass['classes'] = [row.get('classes'+suffix)]\n",
    "    \n",
    "    if len(userClass):\n",
    "        regulation['userClass'] = userClass\n",
    "        \n",
    "    timeSpans = {}\n",
    "     \n",
    "    #Start with the timing:\n",
    "    if row.get('days_of_week.days'+suffix):\n",
    "        timeSpans['daysOfWeek'] = {\n",
    "            'days' : [x.strip() for x in row.get('days_of_week.days'+suffix).split(\",\")]\n",
    "        }\n",
    "        \n",
    "    if row.get('time_of_day.from'+suffix):\n",
    "        timeSpans['timesOfDay'] = [{\n",
    "            'from':row.get('time_of_day.from'+suffix),\n",
    "            'until'  :row.get('time_of_day.to'+suffix) #Could add defaults here if necessary\n",
    "        }]\n",
    "    \n",
    "    if len(timeSpans):\n",
    "        regulation['timeSpans'] = [timeSpans]\n",
    "    else:\n",
    "        regulation['timeSpans'] = []\n",
    "        \n",
    "    # Now check if there are other days or other times of day:\n",
    "    for suffix2 in ['b','c','d','e','f','g','h','i']:\n",
    "        new_timeSpans = {}\n",
    "            \n",
    "        if row.get('days_of_week.days'+suffix+suffix2):\n",
    "            new_timeSpans['daysOfWeek'] = {\n",
    "                'days': [x.strip() for x in row.get('days_of_week.days'+suffix+suffix2).split(\",\")]\n",
    "            }\n",
    "\n",
    "\n",
    "        if row.get('time_of_day.from'+suffix+suffix2):\n",
    "            if 'daysOfWeek' in new_timeSpans and regulation['timeSpans'][len(regulation[\"timeSpans\"])-1]['daysOfWeek'] == new_timeSpans['daysOfWeek']:\n",
    "                regulation['timeSpans'][len(regulation[\"timeSpans\"])-1]['timesOfDay'].append({\n",
    "                    'from': row.get('time_of_day.from' + suffix + suffix2),\n",
    "                    'until': row.get('time_of_day.to' + suffix + suffix2) # Could add defaults here if necessary\n",
    "                })\n",
    "                \n",
    "                del new_timeSpans['daysOfWeek']\n",
    "            else:\n",
    "                new_timeSpans['timesOfDay'] = [{\n",
    "                    'from':row.get('time_of_day.from'+suffix+suffix2),\n",
    "                    'until'  :row.get('time_of_day.to'+suffix+suffix2) #Could add defaults here if necessary\n",
    "                }]\n",
    "\n",
    "        if new_timeSpans:\n",
    "            regulation['timeSpans'].append(new_timeSpans)\n",
    "\n",
    "    for ts in regulation['timeSpans']:\n",
    "        if 'daysOfWeek' in ts:\n",
    "            if len(ts['daysOfWeek']['days']) == 7:\n",
    "                del ts['daysOfWeek']\n",
    "            \n",
    "    payment = {}\n",
    "    \n",
    "    if row.get('payment_min' + suffix):\n",
    "        payment = {\n",
    "            'rates': [\n",
    "                {\n",
    "                    'fees': list(map(float, filter(lambda x: x is not \"\", [row.get('payment_min' + suffix), row.get('payment_max' + suffix)]))),\n",
    "                    'durations': list(map(int, filter(lambda x: x is not \"\", [row.get('payment_min_interval' + suffix), row.get('payment_max_interval' + suffix)])))\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if len(payment['rates'][0]['fees']) == 0:\n",
    "            del payment['rates'][0]['fees']\n",
    "\n",
    "        if len(payment['rates'][0]['durations']) == 0:\n",
    "            del payment['rates'][0]['durations']\n",
    "\n",
    "    if row.get('method'+suffix):\n",
    "        payment['method'] = row.get('method'+suffix)\n",
    "        \n",
    "    if row.get('payment_form'+suffix):\n",
    "        payment['paymentForm'] = row.get('payment_form'+suffix)\n",
    "        \n",
    "    if len(payment):\n",
    "        regulation['payment'] = payment\n",
    "        \n",
    "    if row.get('priority'+suffix):\n",
    "        regulation['priority'] = int(row.get('priority'+suffix))\n",
    "    \n",
    "    return [regulation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Runs everything\n",
    "import csv\n",
    "import json\n",
    "\n",
    "output_rows = []\n",
    "with open('prepped_data.csv','r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if row['location_start'].strip():\n",
    "            line_count +=1;\n",
    "            if line_count <= ROWS_TO_PROCESS:\n",
    "                try:\n",
    "                    #object level\n",
    "                    obj = {\n",
    "                        'location': {\n",
    "                            'coordinates': json.loads(row['coordinates']),\n",
    "                            'shstRefId':row['ShStRefID'],\n",
    "                            'shstLocationSt':float(row['location_start']),\n",
    "                            'shstLocationEnd':float(row['location_end']),\n",
    "                            'sideOfStreet':row['sideOfStreet'],\n",
    "                            'objectId': row['SpaceID'],\n",
    "                            'derivedFrom': row['derived_from'].split(\",\"),\n",
    "                            'marker': row['marker'],\n",
    "                            'streetName': row['streetName']\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    obj['regulations'] = get_regulations(row,\"\")\n",
    "\n",
    "                    for i in range(2, MAX_RULES + 1):\n",
    "                        if row.get(\"zone_\"+str(i)):\n",
    "                            obj['regulations'].extend(get_regulations(row,i))\n",
    "\n",
    "                    if len(obj['regulations']):\n",
    "                        output_rows.append(copy.deepcopy(obj))\n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(row)\n",
    "                    # raise\n",
    "\n",
    "\n",
    "with open('output.json','w') as outFile:\n",
    "    json.dump(output_rows,outFile,indent=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_rows_geojson = []\n",
    "\n",
    "for item in output_rows:\n",
    "    coordinates = item['location'].pop('coordinates')\n",
    "    output_rows_geojson.append({\n",
    "        'type':\"Feature\",\n",
    "        'geometry':{\n",
    "            'type':\"LineString\",\n",
    "            'coordinates': coordinates\n",
    "        },\n",
    "        'properties': item\n",
    "        \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.geojson','w') as outFile:\n",
    "    json.dump({'type':'FeatureCollection','features':output_rows_geojson},outFile,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
